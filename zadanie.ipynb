{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n",
      "Liczba użytkowników: 943, Liczba filmów: 1682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=columns)\n",
    "\n",
    "print(ratings.head())\n",
    "\n",
    "\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "print(f\"Liczba użytkowników: {num_users}, Liczba filmów: {num_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzenie macierzy użytkownik-film:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                              ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "\n",
      "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "user_id                                                              \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix = ratings.pivot(index='user_id', columns='item_id', values='rating')\n",
    "\n",
    "# Podgląd macierzy\n",
    "print(user_item_matrix.head())\n",
    "\n",
    "# Zapisanie macierzy do pliku CSV\n",
    "user_item_matrix.to_csv('user_item_matrix.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486126\n"
     ]
    }
   ],
   "source": [
    "print(user_item_matrix.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcjonalna normlaizacja ocen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix_normalized = user_item_matrix.subtract(user_item_matrix.mean(axis=1), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład faktoryzacji macierzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ustawienia\n",
    "num_users, num_items = user_item_matrix.shape\n",
    "num_features = 10  # Liczba ukrytych wymiarów\n",
    "learning_rate = 0.01\n",
    "reg_param = 0.1  # Parametr regularyzacji\n",
    "epochs = 100\n",
    "\n",
    "# Inicjalizacja macierzy P i Q\n",
    "P = np.random.normal(scale=1./num_features, size=(num_users, num_features))\n",
    "Q = np.random.normal(scale=1./num_features, size=(num_items, num_features))\n",
    "\n",
    "# Konwersja macierzy na NumPy\n",
    "ratings = user_item_matrix.to_numpy()\n",
    "\n",
    "# SGD\n",
    "for epoch in range(epochs):\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_items):\n",
    "            if not np.isnan(ratings[i, j]):\n",
    "                error = ratings[i, j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                for k in range(num_features):\n",
    "                    P[i, k] += learning_rate * (error * Q[j, k] - reg_param * P[i, k])\n",
    "                    Q[j, k] += learning_rate * (error * P[i, k] - reg_param * Q[j, k])\n",
    "\n",
    "    # Obliczanie straty \n",
    "    loss = 0\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_items):\n",
    "            if not np.isnan(ratings[i, j]):\n",
    "                loss += (ratings[i, j] - np.dot(P[i, :], Q[j, :].T))**2\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Wynikowa macierz\n",
    "predicted_ratings = np.dot(P, Q.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodano kod testujący"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Wczytanie danych\n",
    "ratings_train = pd.read_csv('ml-100k/u1.base', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings_test = pd.read_csv('ml-100k/u1.test', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Parametry macierzy\n",
    "num_users = ratings_train['user_id'].nunique()\n",
    "num_items = ratings_train['item_id'].nunique()\n",
    "num_features = 10  # Liczba ukrytych wymiarów\n",
    "learning_rate = 0.01\n",
    "reg_param = 0.1  # Parametr regularyzacji\n",
    "epochs = 100\n",
    "\n",
    "# Tworzenie macierzy użytkownik-film\n",
    "train_matrix = ratings_train.pivot(index='user_id', columns='item_id', values='rating')\n",
    "train_matrix = train_matrix.to_numpy()\n",
    "\n",
    "# Inicjalizacja macierzy P i Q\n",
    "P = np.random.normal(scale=1./num_features, size=(num_users, num_features))\n",
    "Q = np.random.normal(scale=1./num_features, size=(num_items, num_features))\n",
    "\n",
    "# Faktoryzacja macierzy (SGD)\n",
    "for epoch in range(epochs):\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_items):\n",
    "            if not np.isnan(train_matrix[i, j]):  # Pomijamy brakujące oceny\n",
    "                error = train_matrix[i, j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                for k in range(num_features):\n",
    "                    P[i, k] += learning_rate * (error * Q[j, k] - reg_param * P[i, k])\n",
    "                    Q[j, k] += learning_rate * (error * P[i, k] - reg_param * Q[j, k])\n",
    "\n",
    "# Wynikowa macierz\n",
    "predicted_ratings = np.dot(P, Q.T)\n",
    "\n",
    "# Sprawdzanie jakości na zbiorze testowym\n",
    "test_ratings = []\n",
    "predicted_test_ratings = []\n",
    "\n",
    "for _, row in ratings_test.iterrows():\n",
    "    user = row['user_id'] - 1  # Indeksy w zbiorze zaczynają się od 1\n",
    "    item = row['item_id'] - 1\n",
    "    true_rating = row['rating']\n",
    "    predicted_rating = predicted_ratings[user, item]\n",
    "    \n",
    "    test_ratings.append(true_rating)\n",
    "    predicted_test_ratings.append(predicted_rating)\n",
    "\n",
    "# Obliczanie błędu MSE\n",
    "mse = mean_squared_error(test_ratings, predicted_test_ratings)\n",
    "print(f\"Mean Squared Error (MSE) na zbiorze testowym: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 727023.0338\n",
      "Epoch 2/50, Loss: 195330.9757\n",
      "Epoch 3/50, Loss: 94376.2321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wczytanie danych\n",
    "ratings_train = pd.read_csv('ml-100k/u1.base', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings_test = pd.read_csv('ml-100k/u1.test', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Parametry macierzy\n",
    "num_users = ratings_train['user_id'].nunique()\n",
    "num_items = ratings_train['item_id'].nunique()\n",
    "num_features = 10  # Liczba ukrytych wymiarów\n",
    "learning_rate = 0.01\n",
    "reg_param = 0.1  # Parametr regularyzacji\n",
    "epochs = 50  # Zmniejszona liczba epok dla szybszego treningu\n",
    "\n",
    "# Tworzenie macierzy użytkownik-film\n",
    "train_matrix = ratings_train.pivot(index='user_id', columns='item_id', values='rating')\n",
    "train_matrix = train_matrix.to_numpy()\n",
    "\n",
    "# Inicjalizacja macierzy P i Q\n",
    "P = np.random.normal(scale=1./num_features, size=(num_users, num_features))\n",
    "Q = np.random.normal(scale=1./num_features, size=(num_items, num_features))\n",
    "\n",
    "# Faktoryzacja macierzy (SGD)\n",
    "loss_history = []  # Historia strat dla wizualizacji\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_items):\n",
    "            if not np.isnan(train_matrix[i, j]):  # Pomijamy brakujące oceny\n",
    "                error = train_matrix[i, j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                loss += error**2\n",
    "                for k in range(num_features):\n",
    "                    P[i, k] += learning_rate * (error * Q[j, k] - reg_param * P[i, k])\n",
    "                    Q[j, k] += learning_rate * (error * P[i, k] - reg_param * Q[j, k])\n",
    "    loss_history.append(loss)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Wynikowa macierz\n",
    "predicted_ratings = np.dot(P, Q.T)\n",
    "\n",
    "# Sprawdzanie jakości na zbiorze testowym\n",
    "test_ratings = []\n",
    "predicted_test_ratings = []\n",
    "\n",
    "for _, row in ratings_test.iterrows():\n",
    "    user = row['user_id'] - 1  # Indeksy w zbiorze zaczynają się od 1\n",
    "    item = row['item_id'] - 1\n",
    "    true_rating = row['rating']\n",
    "    predicted_rating = np.clip(predicted_ratings[user, item], 1, 5)  # Przycięcie do skali 1-5\n",
    "    \n",
    "    test_ratings.append(true_rating)\n",
    "    predicted_test_ratings.append(round(predicted_rating))  # Zaokrąglenie do najbliższej oceny\n",
    "\n",
    "# Obliczanie błędu MSE\n",
    "mse = mean_squared_error(test_ratings, predicted_test_ratings)\n",
    "print(f\"Mean Squared Error (MSE) na zbiorze testowym: {mse:.4f}\")\n",
    "\n",
    "# Obliczanie accuracy\n",
    "accuracy = accuracy_score(test_ratings, predicted_test_ratings)\n",
    "print(f\"Accuracy na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "# Wizualizacja strat\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), loss_history, marker='o', label='Loss')\n",
    "plt.title('Historia strat podczas treningu')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Strata')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Histogram rzeczywistych vs przewidywanych ocen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(test_ratings, bins=5, alpha=0.5, label='Rzeczywiste', color='blue', density=True)\n",
    "plt.hist(predicted_test_ratings, bins=5, alpha=0.5, label='Przewidywane', color='orange', density=True)\n",
    "plt.title('Porównanie rozkładu ocen (Rzeczywiste vs Przewidywane)')\n",
    "plt.xlabel('Ocena')\n",
    "plt.ylabel('Gęstość')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
